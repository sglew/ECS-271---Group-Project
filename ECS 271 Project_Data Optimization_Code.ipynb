{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7a9240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26fbea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing rows 0-10000\n",
      "Processing rows 10000-20000\n",
      "Processing rows 20000-30000\n",
      "Processing rows 30000-40000\n",
      "Processing rows 40000-50000\n",
      "Processing rows 50000-60000\n",
      "Processing rows 60000-70000\n",
      "Processing rows 70000-80000\n",
      "Processing rows 80000-90000\n",
      "Processing rows 90000-100000\n",
      "Processing rows 100000-110000\n",
      "Processing rows 110000-120000\n",
      "Processing rows 120000-130000\n",
      "Processing rows 130000-140000\n",
      "Processing rows 140000-150000\n",
      "Processing rows 150000-160000\n",
      "Processing rows 160000-170000\n",
      "Processing rows 170000-180000\n",
      "Processing rows 180000-190000\n",
      "Processing rows 190000-200000\n",
      "Processing rows 200000-210000\n",
      "Processing rows 210000-220000\n",
      "Processing rows 220000-230000\n",
      "Processing rows 230000-240000\n",
      "Processing rows 240000-250000\n",
      "Processing rows 250000-260000\n",
      "Processing rows 260000-270000\n",
      "Processing rows 270000-280000\n",
      "Processing rows 280000-290000\n",
      "Processing rows 290000-300000\n",
      "Processing rows 300000-310000\n",
      "Processing rows 310000-320000\n",
      "Processing rows 320000-330000\n",
      "Processing rows 330000-340000\n",
      "Processing rows 340000-350000\n",
      "Processing rows 350000-360000\n",
      "Processing rows 360000-370000\n",
      "Processing rows 370000-380000\n",
      "Processing rows 380000-390000\n",
      "Processing rows 390000-400000\n",
      "Processing rows 400000-410000\n",
      "Processing rows 410000-420000\n",
      "Processing rows 420000-430000\n",
      "Processing rows 430000-440000\n",
      "Processing rows 440000-450000\n",
      "Processing rows 450000-460000\n",
      "Processing rows 460000-470000\n",
      "Processing rows 470000-480000\n",
      "Processing rows 480000-490000\n",
      "Processing rows 490000-500000\n",
      "Processing rows 500000-510000\n",
      "Processing rows 510000-520000\n",
      "Processing rows 520000-530000\n",
      "Processing rows 530000-540000\n",
      "Processing rows 540000-550000\n",
      "Processing rows 550000-560000\n",
      "Processing rows 560000-569106\n",
      "All videos saved incrementally!\n"
     ]
    }
   ],
   "source": [
    "# Download the optimized data file into a folder. Use this code to create a folder of files. \n",
    "# The files are grouped by video, as each video has a number of frames associated with it. \n",
    "\n",
    "parquet_file = \"emotion_landmark_dataset.parquet\"\n",
    "output_dir = \"video_frames_npz\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "x_cols = [f\"x_{i}\" for i in range(478)]\n",
    "y_cols = [f\"y_{i}\" for i in range(478)]\n",
    "z_cols = [f\"z_{i}\" for i in range(478)]\n",
    "\n",
    "chunk_size = 10000  # adjust to your memory\n",
    "\n",
    "# Dictionary to accumulate frames per video\n",
    "video_data = {}\n",
    "\n",
    "lf = pl.scan_parquet(parquet_file)\n",
    "total_rows = lf.select(pl.len()).collect()[0, 0]\n",
    "\n",
    "def append_to_npz(filename, coords, emotions, frame_nums):\n",
    "    if os.path.exists(filename):\n",
    "        # Load old arrays and concatenate\n",
    "        data = np.load(filename, allow_pickle=True)  # <-- allow_pickle=True\n",
    "        old_coords = data['coords']\n",
    "        old_emotions = data['emotions']\n",
    "        old_frames = data['frame_nums']\n",
    "\n",
    "        coords = np.concatenate([old_coords, coords], axis=0)\n",
    "        emotions = np.concatenate([old_emotions, emotions], axis=0)\n",
    "        frame_nums = np.concatenate([old_frames, frame_nums], axis=0)\n",
    "\n",
    "    # Save updated arrays\n",
    "    np.savez_compressed(filename, coords=coords, emotions=emotions, frame_nums=frame_nums)\n",
    "\n",
    "for start in range(0, total_rows, chunk_size):\n",
    "    df_chunk = lf.slice(start, chunk_size).collect().to_pandas()\n",
    "    print(f\"Processing rows {start}-{start + len(df_chunk)}\")\n",
    "\n",
    "    for video_name, group in df_chunk.groupby(\"video_filename\", observed=False):\n",
    "        x = group[x_cols].to_numpy(dtype='float32')\n",
    "        y = group[y_cols].to_numpy(dtype='float32')\n",
    "        z = group[z_cols].to_numpy(dtype='float32')\n",
    "        coords = np.stack([x, y, z], axis=-1)\n",
    "        emotions = group[\"emotion\"].to_numpy()\n",
    "        frame_nums = group[\"frame_num\"].to_numpy()\n",
    "\n",
    "        filename = os.path.join(output_dir, f\"{video_name}.npz\")\n",
    "        append_to_npz(filename, coords, emotions, frame_nums)\n",
    "\n",
    "print(\"All videos saved incrementally!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dd6a896a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting file: video_frames_npz/1079_TSI_SAD_XX.flv.npz\n"
     ]
    }
   ],
   "source": [
    "# Testing code. Good to use for implementation. \n",
    "\n",
    "folder = \"video_frames_npz\"\n",
    "\n",
    "# Randomly pick a file\n",
    "file_path = os.path.join(folder, random.choice(os.listdir(folder)))\n",
    "print(\"Inspecting file:\", file_path)\n",
    "\n",
    "# Load the file\n",
    "data = np.load(file_path, allow_pickle=True)\n",
    "\n",
    "# Stored in a (num_frames, 478, 3) tensor. \n",
    "data_coords = data['coords']\n",
    "num_frames = data_coords[:,0,0].size\n",
    "\n",
    "# For a specific frame, grab the x, y and z coordinate data. \n",
    "frame_num = 0\n",
    "x_coords = data_coords[frame_num, :, 0]\n",
    "y_coords = data_coords[frame_num, :, 1]\n",
    "z_coords = data_coords[frame_num, :, 2]\n",
    "\n",
    "# For the specific frame, grab the emotion. \n",
    "frame_emotion = data['emotions'][frame_num]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath",
   "language": "python",
   "name": "sage"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
